{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate, train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this challenge, we will\n",
    "* use PCA to **compress black & white images of famous people**  \n",
    "* use our compressed images as samples for a classification task\n",
    "\n",
    "This time, contrary to the previous K-means challenge:\n",
    "\n",
    "Instead of performing unsupervised learning on **one image** to find patterns **between its pixels** to reduce its unique color numbers, we will work on a dataset of **multiple B&W images** to:\n",
    "\n",
    "- find common patterns **between all images**\n",
    "- reduce the number of \"principal features\" that describe them\n",
    "\n",
    "More precisely, we will try to express each image of our dataset as a **linear combination of principal components** (principal images in this case, if you will) using PCA.\n",
    "\n",
    "To compress our images, we will then **zero out the smallest principal components** and keep only the most important ones in the equation. Each \"reduced linear combination\" will represent an image that has been compressed.  \n",
    "\n",
    "Luckily, because we only removed the least important components, our lower-dimensional projection of the dataset will preserve the maximal data variance between images, so we should still be able to recognize which person is in each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Run the cell below to download a copy of the famous LFW dataset provided by `Sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data, should take around 2min\n",
    "!curl https://wagon-public-datasets.s3-eu-west-1.amazonaws.com/05-Machine-Learning/06-Unsupervised-Learning/face_recognition/data.zip > data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once downloaded, the next cell will unzip the downloaded file into a `data` folder. It should look like this:\n",
    "\n",
    "```bash\n",
    "data\n",
    "‚îî‚îÄ‚îÄ lfw_home\n",
    "    ‚îú‚îÄ‚îÄ joblib\n",
    "    ‚îú‚îÄ‚îÄ lfw\n",
    "    ‚îú‚îÄ‚îÄ pairs.txt\n",
    "    ‚îú‚îÄ‚îÄ pairsDevTest.txt\n",
    "    ‚îî‚îÄ‚îÄ pairsDevTrain.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q data.zip\n",
    "!tree -L 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(data_home='data', min_faces_per_person=70, resize=0.4, funneled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° The **faces** object contains the following:\n",
    "- `faces.images`: images as matrices of **50 x 37 pixels** you can plot \n",
    "- `faces.data`: flattened version of size **1850 x 1** *(50 x 37=1850)* \n",
    "- `faces.target`: number index representing a class among 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Run the cells below to check some basic facts about your data and see some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"- Images shape: {faces.images.shape}\")\n",
    "print(f\"- Data (flattened images) shape: {faces.data.shape}\")\n",
    "print(f\"- Target shape: {faces.target.shape}\")\n",
    "print(f\"- Number of classes: {np.unique(faces.target).shape}\")\n",
    "print(f\"- Each class is a famous person: {', '.join(faces.target_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let‚Äôs see some faces.\n",
    "fig = plt.figure(figsize=(7,10))\n",
    "\n",
    "for i in range(15):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.title(faces.target_names[faces.target[i]], size=11)\n",
    "    plt.imshow(faces.images[i], cmap=plt.cm.gray)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer**: we are aware that this dataset is not diverse at all and we apologize in advance. However, it is very well suited to understand PCA (low pixel count, B&W, only a few categories, faces well centered in the pictures, etc.) so please keep moving forward in this challenge to understand the notion of \"principal component\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Compression with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have **1288** observations (images) and **1850** features (50 √ó 37 pixels).\n",
    "\n",
    "Having so many features for so few observations is not great in Machine Learning; as a rule of thumb, you may want at least: $n_{features} << \\sqrt{n_{observations}}$.\n",
    "\n",
    "**PCA** can help reduce these features to a more manageable size while maintaining most of the information in the data.\n",
    "\n",
    "\n",
    "‚ùì Fit a `PCA` on your **flattened images** to reduce their dimensions to 150 components  \n",
    "üëâ Store your fitted `PCA` in a variable named **pca**  \n",
    "üëâ Then assign their transformation to **data_projected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images were projected onto the first 150 principal components only. \n",
    "\n",
    "Again, what we call components are **directions of maximum variance** of the data. \n",
    "\n",
    "Now, we don't need 1850 pixels anymore to describe each image, but only 150 values ü§ì  \n",
    "\n",
    "A gain by factor of $\\frac{1850}{150} = 12$ üöÄ  \n",
    "\n",
    "‚ùì Look at the shape of your components, and make sure you understand what it represents  \n",
    "‚ùì Look at the shape of your first component, again make sure you understand what it represents  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first component is a vector of 1850 values.  \n",
    "We now have 150 components of 1850 values each.\n",
    "\n",
    "One face is described as a linear combination of those components.\n",
    "\n",
    "Let's reconstruct one image from its reduced representation to see how it works.\n",
    "\n",
    "‚ùì Use `inverse_transform` on your **data_projected** to reconstruct your compressed images  \n",
    "üëâ Store the result in **data_reconstructed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot the 13th picture (George W. Bush) of the reconstructed dataset, and compare it with the original one. \n",
    "\n",
    "<details>\n",
    "    <summary>üí°Hint</summary>\n",
    "Reshape the flattened data into an image of 50 x 37 pixels\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Run the cell below to see a selection of reconstructed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 10))\n",
    "\n",
    "for i in range(15):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "\n",
    "    # Display each image with a title, which we grab from the dataset\n",
    "    plt.title(faces.target_names[faces.target[i]], size=11)\n",
    "    plt.imshow(pca.inverse_transform(data_projected)[i].reshape((50,37)), cmap=plt.cm.gray)\n",
    "\n",
    "    # Remove plot ticks\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('projection', shape=data_projected.shape)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Investigate your Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot an image that corresponds to the *\\\"mean\\\"* face of the whole dataset  \n",
    "üëâ Use a `gray` color map for your plots in this section\n",
    "\n",
    "<details>\n",
    "    <summary>üí°Hint</summary>\n",
    "    \n",
    "You can use `pca.mean_` or `faces.data.mean(axis=0)`  \n",
    "You will also need some reshaping to be able to plot it as an image\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot the images corresponding to the **first 5** principal components  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Each PC is a flattened \"image\" of 1850 pixels  \n",
    "We merely reshaped them to be able to visualize them as normal images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Below is a list of definitions of these Principal Components  \n",
    "\n",
    "‚ùì **Read them carefully and make sure you understand them**, otherwise consider raising a ticket üéüÔ∏è \n",
    "\n",
    "üí° Your first PCs are the **most important _directions_** on your 1850-feature observations\n",
    "\n",
    "üí° They are the most important **_linear combinations_** of your 1850 pixels\n",
    "\n",
    "üí° The ones which **preserve the most _variance_** when your dataset of pictures is projected onto them  \n",
    "\n",
    "üí° The first few PCs are the **regions of the 2D pixel grid that contain the _most variation_** between your 1288 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot the images corresponding to the **last 5** principal components  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Run the cell below to plot several images corresponding to principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = 3, 5\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(16, 9))\n",
    "\n",
    "for i in range(n_rows * n_cols):\n",
    "    ax = axs[i // n_cols, i % n_cols]\n",
    "    ax.set_title(f'PC {i * 10 + 1}', size=12)\n",
    "    ax.set_xticks(()), ax.set_yticks(())\n",
    "    ax.imshow(pca.components_[i * 10].reshape(50, 37), cmap='gray')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Take some time to look at the PCs and strengthen your intuition on what they represent  \n",
    "\n",
    "Notice that the first PCs capture the biggest/simplest patterns that explain most of the difference between images:\n",
    "- Orientation of the face: looking left, right, up, or down\n",
    "- Size of the face, mouth, nose, and eyes\n",
    "\n",
    "While the last PCs capture the smallest/most detailed patterns:\n",
    "- The shape of the mouth (moving or still)\n",
    "- The structure of the chin\n",
    "\n",
    "Every image can be represented by the \"mean face\" plus a linear combination of the 150 \"PC faces\".\n",
    "\n",
    "If you want to go further check the optional section **Reconstruction of an Original Image**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Choose the Optimal Number of Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encounter, as is often the case in Machine Learning, a trade-off ‚öñÔ∏è\n",
    "\n",
    "**Lots of components** will give a compressed image that is:  \n",
    "üôÇ Close to the original image in terms of quality  \n",
    "üôÅ Not significantly lighter than the original image\n",
    "\n",
    "**A few components** will give a compressed image that is:  \n",
    "üôÇ Significantly lighter than the original\n",
    "üôÅ Far from the original image in terms of quality\n",
    "\n",
    "It is very important to find how many components are needed to describe the data without losing too much information  \n",
    "\n",
    "We can determine this visually by plotting the cumulative sum of explained variance ratio as a function of the number of components  \n",
    "\n",
    "This information is stored in the `explained_variance_ratio_` attribute of a fitted `PCA` object from `sklearn`   \n",
    "\n",
    "‚ùì Plot the cumulative sum of explained variance ratio against the number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è This curve quantifies how much of the total variance is contained within the first components  \n",
    "\n",
    "‚ùì Run the cell below and take some time to confirm the statements with your understanding of the graph:  \n",
    "- The **first component** alone is enough to explain close to **20% of the variance**\n",
    "- The first **25 components** are enough to explain close to **75% of the variance**\n",
    "- We need about **94 components** to describe **90% of the variance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(range(1, pca.n_components_+1), np.cumsum(pca.explained_variance_ratio_))\n",
    "\n",
    "# Set labels\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "\n",
    "# Display grid in the background\n",
    "plt.grid()\n",
    "\n",
    "# Set the limits for the axes\n",
    "plt.xlim((0, 151))\n",
    "plt.ylim((0, 1))\n",
    "\n",
    "# Add lines to the plot\n",
    "plt.hlines(\n",
    "    y=[.75, .9],\n",
    "    xmin=[-5, -5],\n",
    "    xmax=[25, 94],\n",
    "    linestyles='dotted',\n",
    "    colors=['red', 'orange'],\n",
    "    linewidth=2\n",
    ")\n",
    "plt.vlines(\n",
    "    x=[25, 94],\n",
    "    ymin=[0, 0],\n",
    "    ymax=[.75, .9],\n",
    "    linestyles='dotted',\n",
    "    colors=['red', 'orange'],\n",
    "    linewidth=2\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the smallest number of components you need to keep to get _at least_ 80% of the variance?  \n",
    "üëâ  Assign your answer to a variable named `minimal_pc_count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('components', min_pc = minimal_pc_count)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Classify Images (PCA as Feature Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to use **PCA** as a tool for **supervised ML**  .\n",
    "\n",
    "Here is your brief üëá\n",
    "\n",
    "Given a picture of the face of a famous person among a selection, your model should be able to tell to whom the face belongs.  \n",
    "\n",
    "Translating this brief into ML terms üëá\n",
    "- Your samples are images\n",
    "- Your features are their pixels\n",
    "- Your target is a class among several (7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Cross-validate a model of your choice, suited for the classification task at hand    \n",
    "üëâ Record the time needed to train and evaluate your model\n",
    "\n",
    "<details span='markdown'>\n",
    "    <summary>üí°Hint </summary>\n",
    "You can use the following method to record execution time:\n",
    "    \n",
    "```python\n",
    "from time import time\n",
    "start = time()\n",
    "# CODE for which you want to record execution time\n",
    "execution_time = time() - start\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Follow the same steps, this time using the projections of your images as features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Compare your scores and execution times  \n",
    "\n",
    "The quality of your model should have *slightly* decreased.  \n",
    "The time needed to *\\\"choose\\\"* (train and evaluate) the model, however, should have *greatly* decreased!\n",
    "\n",
    "From a business point of view, this is a great achievement üèÜ  \n",
    "As you will discover during the ML Ops module, training models comes at a cost üí∏üôà"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Search for the Optimal Number of Components\n",
    "\n",
    "*This time, the Machine Learning way: Grid Search*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° Now that we have a supervised (features-target) ML setting, we can grid search the optimal number of components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Before proceeding, hold out 30% of your data as a test set  \n",
    "\n",
    "üëâ As usual, assign your split data to `X_train`, `X_test`, `y_train`, `y_test`  \n",
    "üëâ In your `train_test_split`, use `random_state=42` to compare results with your buddy\n",
    "\n",
    "üí° We will **select** our model by **cross-validating** on the **train set**  \n",
    "Then we will **assess** our model by **scoring** it on the **test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° A grid search calls for a pipeline  \n",
    "‚ùì Use [`make_pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html) to create a pipeline with two steps:\n",
    "- A `PCA`, no need to choose the number of components now\n",
    "- The [`SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) algorithm as an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a cross-validated grid search that uses your pipeline  \n",
    "üëâ Search only for the number of components for your `PCA` among these options: `[50, 100, 200, 300]`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Print the [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report) of your best model  \n",
    "üëâ Use the `best estimator` from your grid search to obtain predictions from **X_test**  \n",
    "üëâ Use these predictions against **y_test** to print your classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may get an UndefinedMetricWarning if for one of the classes, there are no correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì How many components give the best score?  \n",
    "üëâ Assign the value to a variable named **best_n_components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('search_components', best_pc=best_n_components)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) What about Scaling, Balancing and Tuning?\n",
    "\n",
    "*The complete Machine Learning pipeline*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focused extensively on PCA but there are 3 ML methods you can use to enhance your score:\n",
    "- Scale your data before applying PCA\n",
    "- Use some form of balancing as your classes are not balanced\n",
    "- Grid search for optimal hyperparameters for your estimator\n",
    "\n",
    "Let's do it and see how using `PCA` alongside the ML tricks we have seen so far will help us achieve a higher score\n",
    "\n",
    "‚ùì Run the cell below to see both your baseline and base score obtained with only PCA + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = pd.Series(y).value_counts(normalize=True).max()\n",
    "\n",
    "score_base = cross_validate(\n",
    "    make_pipeline(\n",
    "        PCA(n_components=best_n_components),\n",
    "        SVC()\n",
    "    ),\n",
    "    X, y,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")['test_score'].mean()\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "    Accuracy scores:\n",
    "    Baseline (frequency of most frequent class): {baseline: .2%}\n",
    "    Base Model (PCA + SVC): {score_base:.2%}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Scale your data before reduction with a `PCA`  \n",
    "üëâ Build a pipeline that has 3 steps:\n",
    "- Scaling with `StandardScaler`\n",
    "- Reduction with `PCA` (use **best_n_components** from your earlier search)\n",
    "- Prediction with `SVC` (keep all default arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Cross-validate your pipeline on the full **X** and **y** over 3 folds  \n",
    "üëâ Store the mean score in **score_scaling**  \n",
    "üëâ Check your new score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Up we go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Check the spread of your target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è As you can see, your classes are highly unbalanced  \n",
    "\n",
    "The most represented class appears on 41% of images  \n",
    "While the least represented one appears on 5.5% of images  \n",
    "\n",
    "This will cause your model to predict the most represented class too often, which will decrease\n",
    "- the precision score for the most represented classes \n",
    "- the recall score for the least represented classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Train another pipeline that takes into account your class imbalance  \n",
    "üëâ Check the [documentation of the SVC estimator](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)  \n",
    "üëâ Find and use the parameter that helps with the class imbalance in your SVC  \n",
    "üëâ Store the mean score in **score_balanced** and check your new score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöÄ Sky is the limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Fine-tune your model to find the combination of hyperparameters that yields the highest score  \n",
    "üëâ Search 3 hyperparameters maximum  \n",
    "üëâ For each one, search on 3 values maximum  \n",
    "üëâ Here is an indicative search dictionary you can use:\n",
    "```python\n",
    "grid = {\n",
    "        'svc__kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "        'svc__gamma': [1e-4, 1e-3, 1e-2],\n",
    "        'svc__C': [10, 1e2, 1e3]\n",
    "}\n",
    "```\n",
    "‚ÑπÔ∏è These ranges of hyperparameters are examples and are not meant to offer the combination for the best model. Feel free to change the values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'svc__kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'svc__gamma': [1e-4, 1e-3, 1e-2],\n",
    "    'svc__C': [10, 1e2, 1e3]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipe_balanced, \n",
    "    grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "search.fit(X, y)\n",
    "score_tuned = search.best_score_\n",
    "round(score_tuned, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöÄ We increased accuracy by 10 points compared to our base model  \n",
    "\n",
    "With a dimensionality reduction technique, such as `PCA`, it is faster to train, cross-validate and fine-tune our models  \n",
    "\n",
    "Fine-tuning can be extremely long, being able to speed up the process by using a reduction on our data beforehand is a great advantage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'full_pipeline',\n",
    "    score_scaled=score_scaling,\n",
    "    score_balanced=score_balanced,\n",
    "    score_tuned=score_tuned\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ **Don't forget to push your notebook.**  \n",
    "\n",
    "Proceed with the challenges of the day and come back here if you have time üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary markdown='span'>üçî Food for thought</summary>\n",
    "\n",
    "You can try to compare the result of the PCA-preprocessed classification with the one that was not preprocessed to see if\n",
    "1. it is quicker\n",
    "2. it is better\n",
    "3. it helps find a linear separation\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) (Optional) Reconstruction of an Original Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Study the cells below which reconstruct the image step by step without `inverse_transform`  \n",
    "\n",
    "üëâ We start by selecting a single image for the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's reconstruct the 13th image\n",
    "image_original = faces.images[12];\n",
    "image_compressed = data_projected[12];\n",
    "\n",
    "plt.imshow(image_original, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ We manually do the sum of multiplications $X\\_reconstructed_{i} = \\sum_{i=1}^{n\\_components}{X_{projected_i} * W_i}$  \n",
    "$W_i$ being the `i-th principal component`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start the reconstruction from the mean of all images\n",
    "image_reconstructed = pca.mean_.copy(); \n",
    "\n",
    "# Then, reconstruct the image by computing the sum of every 150 entries of its compressed representation, weighted by the corresponding principal components\n",
    "reconstruction = list()\n",
    "\n",
    "for i in range(pca.n_components_):\n",
    "    image_reconstructed += pca.components_[i] * image_compressed[i]\n",
    "    reconstruction.append(image_reconstructed.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ We plot the reconstructed image alongside the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original and the compressed image.\n",
    "fig, ax = plt.subplots(1, 2, figsize = (5, 5))\n",
    "\n",
    "# Original\n",
    "ax[0].imshow(image_original, cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "\n",
    "# Reconstructed\n",
    "ax[1].imshow(image_reconstructed.reshape(faces.images[0].shape), cmap='gray')\n",
    "ax[1].set_title('Compressed reconstructed Image')\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ We plot the image at different steps of reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot several images at different steps of reconstruction\n",
    "n_rows, n_cols = 3, 5\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(16, 9))\n",
    "plt.suptitle('Image reconstructed using only...')\n",
    "\n",
    "for i in range(n_rows * n_cols):\n",
    "    ax = axs[i // n_cols, i % n_cols]\n",
    "    ax.set_title(f'... {i * 10 + 1} PC', size=12)\n",
    "    ax.set_xticks(()), ax.set_yticks(())\n",
    "    ax.imshow(reconstruction[i * 10].reshape(50, 37), cmap='gray')\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
